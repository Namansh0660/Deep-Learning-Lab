{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## DL Lab - 2\n","- Name: Namansh Singh Maurya\n","- RegNo: 22MIA1034"],"metadata":{"id":"ePEn_ZvJ9tU4"}},{"cell_type":"markdown","source":["ReLu - rectified linear unit (activation function), used in hidden layer of deep neural network"],"metadata":{"id":"cfjSvusnJSG9"}},{"cell_type":"markdown","source":["value (0-1), less than 0.5 is equal to 0 and more than 0.5 is equal to 1"],"metadata":{"id":"ijzH-6AiJw6v"}},{"cell_type":"markdown","source":["In ML, if size of the dataset increases then dimensionality of ML algorithm also increases (sparse:existance of 0 values), leading to wrong predictions. So we use DL algo Tensorflow for dense representation"],"metadata":{"id":"FJe_W6-qNO3n"}},{"cell_type":"markdown","source":["# Importing Libraries"],"metadata":{"id":"SAFzuKqzzSdQ"}},{"cell_type":"code","source":["import numpy as np # number pyhton, helps to create matrix representaion from data form\n","from numpy import loadtxt # func loadtxt - to read dataset from csv in matrix form\n","from tensorflow.keras.models import Sequential # for deep neural network, sub-packege: keras, sub-sub-package: models and model chosen is sequential\n","from tensorflow.keras.layers import Dense # dense layer\n","import pandas as pd"],"metadata":{"id":"cBe0d6UrKOTK","executionInfo":{"status":"ok","timestamp":1741287278730,"user_tz":-330,"elapsed":2,"user":{"displayName":"Namansh Singh Maurya","userId":"06941414300254614726"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# Loading dataset"],"metadata":{"id":"knlw3Nz1zWqO"}},{"cell_type":"code","source":["df = loadtxt('/content/diabetes (1).csv', delimiter=',', skiprows=1)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nE2Pa6OPzVie","executionInfo":{"status":"ok","timestamp":1741287278739,"user_tz":-330,"elapsed":6,"user":{"displayName":"Namansh Singh Maurya","userId":"06941414300254614726"}},"outputId":"f9ba5ea5-f265-402f-a4e2-c7994ed40ed4"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n","       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n","       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n","       ...,\n","       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n","       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n","       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["# Model Building"],"metadata":{"id":"oeDbOsO5za8K"}},{"cell_type":"code","source":["x = df[:,0:8] # first eight columns 0-7 are stored in x\n","y = df[:,8] # eigth column is stored in y\n","model = Sequential() # making dl model which is going to learn sequentially\n","model.add(Dense(12, input_shape = (8,), activation='relu')) # adding dense layers, 1st hidden layers needs more neurons than the other hidden layers\n","model.add(Dense(8, activation='relu')) # 2nd hidden layer\n","model.add(Dense(1, activation='sigmoid')) # output layer, sigmoid: predicting 0 or 1"],"metadata":{"id":"6F-zniV0Kd02","executionInfo":{"status":"ok","timestamp":1741287278752,"user_tz":-330,"elapsed":11,"user":{"displayName":"Namansh Singh Maurya","userId":"06941414300254614726"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["# Model Training"],"metadata":{"id":"Qgutj8d9zg4R"}},{"cell_type":"code","source":["# Training\n","model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy']) # loss: difference between expectation and prediction\n","model.fit(x, y, epochs=128, batch_size=10)\n","loss, accuracy = model.evaluate(x, y)\n","print('Loss: ', loss)\n","print('Accuracy: ', accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RHq0Tax_Qfb8","outputId":"2b0ca6bb-550d-4c82-9980-88c9646d9238","executionInfo":{"status":"ok","timestamp":1741287315939,"user_tz":-330,"elapsed":37185,"user":{"displayName":"Namansh Singh Maurya","userId":"06941414300254614726"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3752 - loss: 24.4333\n","Epoch 2/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5940 - loss: 1.8021\n","Epoch 3/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6137 - loss: 1.4574\n","Epoch 4/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6448 - loss: 1.2671\n","Epoch 5/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6313 - loss: 1.1570\n","Epoch 6/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6369 - loss: 0.9068\n","Epoch 7/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6424 - loss: 0.8199\n","Epoch 8/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6422 - loss: 0.8421\n","Epoch 9/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6807 - loss: 0.7751\n","Epoch 10/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6606 - loss: 0.7412\n","Epoch 11/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6437 - loss: 0.7119\n","Epoch 12/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6846 - loss: 0.7198\n","Epoch 13/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6562 - loss: 0.7024\n","Epoch 14/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6928 - loss: 0.6216\n","Epoch 15/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6279 - loss: 0.7185\n","Epoch 16/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6817 - loss: 0.6619\n","Epoch 17/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6823 - loss: 0.6280\n","Epoch 18/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6927 - loss: 0.6460\n","Epoch 19/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6993 - loss: 0.6428\n","Epoch 20/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6846 - loss: 0.6206\n","Epoch 21/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6569 - loss: 0.6941\n","Epoch 22/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6592 - loss: 0.6845\n","Epoch 23/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6748 - loss: 0.6537\n","Epoch 24/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6659 - loss: 0.6582\n","Epoch 25/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6761 - loss: 0.6032\n","Epoch 26/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7163 - loss: 0.5944\n","Epoch 27/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7083 - loss: 0.5734\n","Epoch 28/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6995 - loss: 0.6479\n","Epoch 29/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6862 - loss: 0.6095\n","Epoch 30/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7004 - loss: 0.5903\n","Epoch 31/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6904 - loss: 0.5882\n","Epoch 32/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7123 - loss: 0.6100\n","Epoch 33/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7184 - loss: 0.6010\n","Epoch 34/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6968 - loss: 0.5860\n","Epoch 35/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7183 - loss: 0.5594\n","Epoch 36/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6852 - loss: 0.6031\n","Epoch 37/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7287 - loss: 0.5905\n","Epoch 38/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6884 - loss: 0.6295\n","Epoch 39/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7483 - loss: 0.5239\n","Epoch 40/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7051 - loss: 0.5835\n","Epoch 41/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7085 - loss: 0.5759\n","Epoch 42/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7220 - loss: 0.5659\n","Epoch 43/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7000 - loss: 0.5922\n","Epoch 44/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7212 - loss: 0.5737\n","Epoch 45/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6811 - loss: 0.5848\n","Epoch 46/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7036 - loss: 0.5699\n","Epoch 47/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7139 - loss: 0.5762\n","Epoch 48/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7054 - loss: 0.5514\n","Epoch 49/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6946 - loss: 0.6022\n","Epoch 50/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7278 - loss: 0.5348\n","Epoch 51/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7354 - loss: 0.5515\n","Epoch 52/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7648 - loss: 0.5171\n","Epoch 53/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7339 - loss: 0.5445\n","Epoch 54/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.5413\n","Epoch 55/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7364 - loss: 0.5548\n","Epoch 56/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7241 - loss: 0.5506\n","Epoch 57/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7233 - loss: 0.5557\n","Epoch 58/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7267 - loss: 0.5474\n","Epoch 59/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6995 - loss: 0.5637\n","Epoch 60/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7280 - loss: 0.5499\n","Epoch 61/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7496 - loss: 0.5336\n","Epoch 62/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7190 - loss: 0.5778\n","Epoch 63/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7337 - loss: 0.5650\n","Epoch 64/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7186 - loss: 0.5485\n","Epoch 65/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7534 - loss: 0.5254\n","Epoch 66/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7161 - loss: 0.5620\n","Epoch 67/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7146 - loss: 0.5567\n","Epoch 68/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7412 - loss: 0.5476\n","Epoch 69/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7518 - loss: 0.5537\n","Epoch 70/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7720 - loss: 0.5278\n","Epoch 71/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7417 - loss: 0.5145\n","Epoch 72/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7441 - loss: 0.5391\n","Epoch 73/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7511 - loss: 0.5130\n","Epoch 74/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.5224\n","Epoch 75/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7016 - loss: 0.5575\n","Epoch 76/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7466 - loss: 0.5901\n","Epoch 77/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7652 - loss: 0.5049\n","Epoch 78/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7565 - loss: 0.5102\n","Epoch 79/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7349 - loss: 0.5601\n","Epoch 80/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7323 - loss: 0.5454\n","Epoch 81/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7155 - loss: 0.5514\n","Epoch 82/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7298 - loss: 0.5084\n","Epoch 83/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7506 - loss: 0.4966\n","Epoch 84/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7216 - loss: 0.5347\n","Epoch 85/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7118 - loss: 0.5504\n","Epoch 86/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7484 - loss: 0.5312\n","Epoch 87/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7508 - loss: 0.5260\n","Epoch 88/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7158 - loss: 0.5631\n","Epoch 89/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7527 - loss: 0.5156\n","Epoch 90/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7314 - loss: 0.5609\n","Epoch 91/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7501 - loss: 0.5308\n","Epoch 92/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7714 - loss: 0.5182\n","Epoch 93/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7318 - loss: 0.5446\n","Epoch 94/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7603 - loss: 0.5019\n","Epoch 95/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7455 - loss: 0.5432\n","Epoch 96/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7877 - loss: 0.4696\n","Epoch 97/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7633 - loss: 0.5123\n","Epoch 98/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7216 - loss: 0.5507\n","Epoch 99/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7286 - loss: 0.5444\n","Epoch 100/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7495 - loss: 0.5099\n","Epoch 101/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7351 - loss: 0.5552\n","Epoch 102/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7362 - loss: 0.5024\n","Epoch 103/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7400 - loss: 0.5254\n","Epoch 104/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7576 - loss: 0.5238\n","Epoch 105/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7583 - loss: 0.4923\n","Epoch 106/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7607 - loss: 0.5073\n","Epoch 107/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7536 - loss: 0.5060\n","Epoch 108/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7463 - loss: 0.5650\n","Epoch 109/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7527 - loss: 0.5121\n","Epoch 110/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7600 - loss: 0.5069\n","Epoch 111/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7660 - loss: 0.5140\n","Epoch 112/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7603 - loss: 0.5295\n","Epoch 113/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7453 - loss: 0.4995\n","Epoch 114/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7444 - loss: 0.5158\n","Epoch 115/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7317 - loss: 0.5200\n","Epoch 116/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7595 - loss: 0.4988\n","Epoch 117/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7452 - loss: 0.5150\n","Epoch 118/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.5392\n","Epoch 119/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7712 - loss: 0.5089\n","Epoch 120/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7476 - loss: 0.5412\n","Epoch 121/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7620 - loss: 0.4996\n","Epoch 122/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7665 - loss: 0.4794\n","Epoch 123/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7805 - loss: 0.4643\n","Epoch 124/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7658 - loss: 0.4922\n","Epoch 125/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7964 - loss: 0.4740\n","Epoch 126/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7439 - loss: 0.5334\n","Epoch 127/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7543 - loss: 0.5026\n","Epoch 128/128\n","\u001b[1m77/77\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7688 - loss: 0.5046\n","\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7509 - loss: 0.5033  \n","Loss:  0.49230217933654785\n","Accuracy:  0.7643229365348816\n"]}]},{"cell_type":"markdown","source":["# Printing Accuracy"],"metadata":{"id":"7EdMNVBnzi7g"}},{"cell_type":"code","source":["print('Accuracy: %0.2f' % (accuracy*100))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yqfIumz7SNz4","outputId":"802b9c11-2f85-4d44-a140-7a9ca86cedd7","executionInfo":{"status":"ok","timestamp":1741287315954,"user_tz":-330,"elapsed":13,"user":{"displayName":"Namansh Singh Maurya","userId":"06941414300254614726"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 76.43\n"]}]},{"cell_type":"markdown","source":["# Model Testing"],"metadata":{"id":"R1Se-bLazk5A"}},{"cell_type":"code","source":["# Testing\n","input = [6, 148, 72, 35, 0, 33.6, 0.627, 50]\n","input_n = np.array(input).reshape(1, -1) # reshape to model format\n","output = model.predict(input_n)\n","print(output)\n","\n","if(output > 0.5):\n","  print('Diabetic')\n","else:\n","  print('Non-Diabetic')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kkMpJbEvT4w7","outputId":"5def481a-cfad-4770-a398-ce309383c1b6","executionInfo":{"status":"ok","timestamp":1741287316012,"user_tz":-330,"elapsed":57,"user":{"displayName":"Namansh Singh Maurya","userId":"06941414300254614726"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n","[[0.32002884]]\n","Non-Diabetic\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"CRKs6hTXUwxI","executionInfo":{"status":"ok","timestamp":1741287316019,"user_tz":-330,"elapsed":4,"user":{"displayName":"Namansh Singh Maurya","userId":"06941414300254614726"}}},"execution_count":12,"outputs":[]}]}